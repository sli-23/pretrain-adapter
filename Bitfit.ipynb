{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f3b363f92794ec69a2301580d5d8154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d96cb84e8967459c9aeb066206cfeb34",
              "IPY_MODEL_b02b5e5b96094bdfb36e2604a4236ba5",
              "IPY_MODEL_b478a9a55ce447f1890186e1523a7310"
            ],
            "layout": "IPY_MODEL_3327122ee27047d39da02b59e3c57284"
          }
        },
        "d96cb84e8967459c9aeb066206cfeb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d329b1132240cb8148b6b9093a8daa",
            "placeholder": "​",
            "style": "IPY_MODEL_19e8d7c5d1774c70bd32696c28a5c0c5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b02b5e5b96094bdfb36e2604a4236ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb667ca5fafa4378994f3931e0107527",
            "max": 62747391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f77f45446644343a7e5d2baa4e41772",
            "value": 62747391
          }
        },
        "b478a9a55ce447f1890186e1523a7310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0711300c961e4bb2b472f95ce297c02a",
            "placeholder": "​",
            "style": "IPY_MODEL_20ada565f8db42e3a9a646a29f8c4334",
            "value": " 62.7M/62.7M [00:00&lt;00:00, 268MB/s]"
          }
        },
        "3327122ee27047d39da02b59e3c57284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d329b1132240cb8148b6b9093a8daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e8d7c5d1774c70bd32696c28a5c0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb667ca5fafa4378994f3931e0107527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f77f45446644343a7e5d2baa4e41772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0711300c961e4bb2b472f95ce297c02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ada565f8db42e3a9a646a29f8c4334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "B-QLwir2KSQf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHKLSUrWKPlA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import warnings\n",
        "import psutil\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1AQxSOKwt-KavXaXwxMw3h9HyDyuYOYAP', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "yiVSXkGqKWd_",
        "outputId": "554d0d4a-8ada-4936-f4df-4a740c4af8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AQxSOKwt-KavXaXwxMw3h9HyDyuYOYAP\n",
            "To: /content/IMDB_Dataset.csv\n",
            "100%|██████████| 66.2M/66.2M [00:01<00:00, 40.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IMDB_Dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BitFit Finetuning"
      ],
      "metadata": {
        "id": "aU6vNg7SOYRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import warnings\n",
        "import psutil\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def prepare_data(tokenizer, texts, labels=None, max_len=128):\n",
        "    encoded_batch = tokenizer.batch_encode_plus(\n",
        "        texts,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_batch['input_ids']\n",
        "    attention_masks = encoded_batch['attention_mask']\n",
        "    labels = torch.tensor(labels) if labels is not None else None\n",
        "\n",
        "    return TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "Sk_rOYYGOpTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv('IMDB_Dataset.csv')\n",
        "\n",
        "# Map labels to integers\n",
        "label_map = {'positive': 1, 'negative': 0}\n",
        "imdb_reviews = train_data[\"review\"].tolist()\n",
        "sentiments = [label_map[label] for label in train_data[\"sentiment\"].tolist()]"
      ],
      "metadata": {
        "id": "6iYCmBNjFw3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta"
      ],
      "metadata": {
        "id": "e2T69rRPGfja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "# Initialize tokenizer\n",
        "model_name = \"deepset/tinyroberta-squad2\"\n",
        "#tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Prepare dataset\n",
        "train_dataset = prepare_data(tokenizer, imdb_reviews, sentiments)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.9 * len(train_dataset))\n",
        "valid_size = len(train_dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
        "\n",
        "# Create data loaders\n",
        "num_workers = 4\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32, num_workers=num_workers)\n",
        "valid_dataloader = DataLoader(valid_dataset, sampler=SequentialSampler(valid_dataset), batch_size=32, num_workers=num_workers)\n",
        "\n",
        "# Load RoBERTa\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "# Initialize optimizer with bias parameters\n",
        "bias_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(bias_params, lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Set up scheduler\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_QOozZcGFvT",
        "outputId": "ab11be44-3097-4ae6-c881-ad5ae54599d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at deepset/tinyroberta-squad2 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BitFitFineTuner(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(BitFitFineTuner, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.freeze_parameters()\n",
        "\n",
        "    def freeze_parameters(self):\n",
        "        for name, param in self.base_model.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, *input, **kwargs):\n",
        "        return self.base_model(*input, **kwargs)"
      ],
      "metadata": {
        "id": "Qxsw9QtUY9A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bitfit_model = BitFitFineTuner(model)\n",
        "bitfit_model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('\\n======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # Track memory usage\n",
        "    mem_before_epoch = psutil.virtual_memory().used / (1024 ** 2)  # Convert to MB for more precision\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        bitfit_model.zero_grad()\n",
        "        outputs = bitfit_model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bitfit_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    mem_after_epoch = psutil.virtual_memory().used / (1024 ** 2)  # Convert to MB for more precision\n",
        "    print(f\"Epoch {epoch_i + 1} Memory used: {mem_after_epoch - mem_before_epoch:.2f} MB\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # Validation step\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    bitfit_model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in valid_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    avg_valid_loss = total_eval_loss / len(valid_dataloader)\n",
        "    avg_val_accuracy = total_eval_accuracy / nb_eval_steps\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_valid_loss))\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ycZ2xMWMuVF",
        "outputId": "4851fb0e-509e-4c40-f3f6-e9a7b474db16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Epoch 1 Memory used: -4.56 MB\n",
            "  Average training loss: 0.67\n",
            "  Training epoch took: 0:01:20\n",
            "Running Validation...\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Epoch 2 Memory used: 9.46 MB\n",
            "  Average training loss: 0.57\n",
            "  Training epoch took: 0:01:20\n",
            "Running Validation...\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Epoch 3 Memory used: -6.82 MB\n",
            "  Average training loss: 0.50\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Epoch 4 Memory used: -29.36 MB\n",
            "  Average training loss: 0.47\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Epoch 5 Memory used: 16.27 MB\n",
            "  Average training loss: 0.46\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Epoch 6 Memory used: 19.35 MB\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Epoch 7 Memory used: 14.09 MB\n",
            "  Average training loss: 0.44\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Epoch 8 Memory used: 19.60 MB\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.42\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Epoch 9 Memory used: 2.79 MB\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.42\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Epoch 10 Memory used: -0.23 MB\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:01:19\n",
            "Running Validation...\n",
            "  Validation Loss: 0.42\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len([param for name, param in bitfit_model.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egMGd3jLaUkK",
        "outputId": "8f7ecd26-2431-4434-b0c6-e0f1749f7b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert"
      ],
      "metadata": {
        "id": "UgMRsSM8GbMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D\n",
        "# TinyBert\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Initialize tokenizer\n",
        "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# Prepare dataset\n",
        "train_dataset = prepare_data(tokenizer, imdb_reviews, sentiments)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.9 * len(train_dataset))\n",
        "valid_size = len(train_dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
        "\n",
        "# Create data loaders\n",
        "num_workers = 4\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32, num_workers=num_workers)\n",
        "valid_dataloader = DataLoader(valid_dataset, sampler=SequentialSampler(valid_dataset), batch_size=32, num_workers=num_workers)\n",
        "\n",
        "\n",
        "# Model and optimizer\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Set up scheduler\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "0f3b363f92794ec69a2301580d5d8154",
            "d96cb84e8967459c9aeb066206cfeb34",
            "b02b5e5b96094bdfb36e2604a4236ba5",
            "b478a9a55ce447f1890186e1523a7310",
            "3327122ee27047d39da02b59e3c57284",
            "a6d329b1132240cb8148b6b9093a8daa",
            "19e8d7c5d1774c70bd32696c28a5c0c5",
            "eb667ca5fafa4378994f3931e0107527",
            "1f77f45446644343a7e5d2baa4e41772",
            "0711300c961e4bb2b472f95ce297c02a",
            "20ada565f8db42e3a9a646a29f8c4334"
          ]
        },
        "id": "LYrDtzCOGikd",
        "outputId": "092ae48a-97e9-4cbc-afce-209fd53ca04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f3b363f92794ec69a2301580d5d8154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bitfit_model = BitFitFineTuner(model)\n",
        "bitfit_model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('\\n======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # Track memory usage\n",
        "    mem_before_epoch = psutil.virtual_memory().used / (1024 ** 2)  # Convert to MB for more precision\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        bitfit_model.zero_grad()\n",
        "        outputs = bitfit_model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bitfit_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    mem_after_epoch = psutil.virtual_memory().used / (1024 ** 2)  # Convert to MB for more precision\n",
        "    print(f\"Epoch {epoch_i + 1} Memory used: {mem_after_epoch - mem_before_epoch:.2f} MB\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # Validation step\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    bitfit_model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in valid_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    avg_valid_loss = total_eval_loss / len(valid_dataloader)\n",
        "    avg_val_accuracy = total_eval_accuracy / nb_eval_steps\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_valid_loss))\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjEPThaxc8A9",
        "outputId": "525c9dae-30f5-4547-d3e8-89c46eca9c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Epoch 1 Memory used: -10.21 MB\n",
            "  Average training loss: 0.69\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Epoch 2 Memory used: 18.06 MB\n",
            "  Average training loss: 0.69\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Epoch 3 Memory used: 54.68 MB\n",
            "  Average training loss: 0.68\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Epoch 4 Memory used: -11.82 MB\n",
            "  Average training loss: 0.68\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Epoch 5 Memory used: -6.10 MB\n",
            "  Average training loss: 0.68\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Epoch 6 Memory used: 10.18 MB\n",
            "  Average training loss: 0.67\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Epoch 7 Memory used: 11.55 MB\n",
            "  Average training loss: 0.67\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Epoch 8 Memory used: 55.43 MB\n",
            "  Average training loss: 0.67\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Epoch 9 Memory used: 27.66 MB\n",
            "  Average training loss: 0.67\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Epoch 10 Memory used: -4.88 MB\n",
            "  Average training loss: 0.67\n",
            "  Training epoch took: 0:00:24\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len([param for name, param in bitfit_model.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BidDbmwLiB36",
        "outputId": "f27ede59-9b36-47ed-a6c5-7672a1417205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}